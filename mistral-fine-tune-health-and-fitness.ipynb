{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-13T20:57:57.098351Z","iopub.execute_input":"2024-03-13T20:57:57.098724Z","iopub.status.idle":"2024-03-13T20:57:58.841363Z","shell.execute_reply.started":"2024-03-13T20:57:57.098692Z","shell.execute_reply":"2024-03-13T20:57:58.840386Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# You only need to run this once per machine\n!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install -q -U datasets==2.16.0\n# !pip install sentencepiece scipy","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:45:49.306645Z","iopub.execute_input":"2024-03-18T14:45:49.306941Z","iopub.status.idle":"2024-03-18T14:48:06.902531Z","shell.execute_reply.started":"2024-03-18T14:45:49.306913Z","shell.execute_reply":"2024-03-18T14:48:06.901515Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ns3fs 2024.2.0 requires fsspec==2024.2.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:48:06.904482Z","iopub.execute_input":"2024-03-18T14:48:06.904779Z","iopub.status.idle":"2024-03-18T14:48:08.496005Z","shell.execute_reply.started":"2024-03-18T14:48:06.904748Z","shell.execute_reply":"2024-03-18T14:48:08.495136Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a52adbeadab4a9f8efde7e6c0b75d9c"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(\"HazSylvia/Fitness_Unformatted\")\ntotal_data = dataset['train'].train_test_split(test_size=0.2)\ntrain_dataset = total_data['train']\neval_dataset = total_data['test']\ntrain_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:48:26.923897Z","iopub.execute_input":"2024-03-18T14:48:26.924288Z","iopub.status.idle":"2024-03-18T14:48:28.984541Z","shell.execute_reply.started":"2024-03-18T14:48:26.924258Z","shell.execute_reply":"2024-03-18T14:48:28.983634Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/161 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99f9e7affec849388ac576ada9ee30b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/379k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4df7ee5e740489c867872f79fbd828f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39fe5af0e7d94647ad85cc5a2a2cae64"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'Human': 'tell be about exercise ball chest stretch',\n 'Assistant': 'the exercise ball chest stretch is a simple stretch for the pectoral muscles that can be made more dynamic with help from a medicine ball it can work in a dynamic warmup paired with movements in a workout or as part of a cooldown or recovery strategy if the stretch causes pain in the front of your shoulder dial back the intensity or choose another chest stretch'}"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset,eval_dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:48:31.856152Z","iopub.execute_input":"2024-03-18T14:48:31.856975Z","iopub.status.idle":"2024-03-18T14:48:31.862881Z","shell.execute_reply.started":"2024-03-18T14:48:31.856943Z","shell.execute_reply":"2024-03-18T14:48:31.861887Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['Human', 'Assistant'],\n     num_rows: 742\n }),\n Dataset({\n     features: ['Human', 'Assistant'],\n     num_rows: 186\n }))"},"metadata":{}}]},{"cell_type":"code","source":"def formatting_func(example):\n    text = f\"\"\" You are a very helpful assitant who helps with Health and Fitness related questions.\\\n    Always assist with care, respect, and truth. Respond with utmost utility yet securely. \\\n    Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity.\\\n    ### Question: {example['Human']} \\n\n    ### Answer: {example['Assistant']} \"\"\"\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:58:17.079794Z","iopub.execute_input":"2024-03-18T14:58:17.080168Z","iopub.status.idle":"2024-03-18T14:58:17.085298Z","shell.execute_reply.started":"2024-03-18T14:58:17.080136Z","shell.execute_reply":"2024-03-18T14:58:17.084283Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nbase_model_id = \"mistralai/Mistral-7B-v0.1\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:58:19.847353Z","iopub.execute_input":"2024-03-18T14:58:19.848141Z","iopub.status.idle":"2024-03-18T14:58:57.093923Z","shell.execute_reply.started":"2024-03-18T14:58:19.848104Z","shell.execute_reply":"2024-03-18T14:58:57.093106Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a560a23ba4ef4a279787e98eb9a2e17d"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    base_model_id,\n    padding_side=\"left\",\n    add_eos_token=True,\n    add_bos_token=True,\n)\ntokenizer.pad_token = tokenizer.eos_token\n\ndef generate_and_tokenize_prompt(prompt):\n    return tokenizer(formatting_func(prompt))","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:58:57.095817Z","iopub.execute_input":"2024-03-18T14:58:57.096673Z","iopub.status.idle":"2024-03-18T14:58:57.242536Z","shell.execute_reply.started":"2024-03-18T14:58:57.096634Z","shell.execute_reply":"2024-03-18T14:58:57.241717Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\ntokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)\ntokenized_train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:58:57.243804Z","iopub.execute_input":"2024-03-18T14:58:57.244282Z","iopub.status.idle":"2024-03-18T14:58:58.010803Z","shell.execute_reply.started":"2024-03-18T14:58:57.244247Z","shell.execute_reply":"2024-03-18T14:58:58.009866Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/742 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"787a421fef7e4cb39f05bd382815eadf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/186 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f68676bb7b28482eb90a811858d6fe09"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'Human': 'tell be about exercise ball chest stretch',\n 'Assistant': 'the exercise ball chest stretch is a simple stretch for the pectoral muscles that can be made more dynamic with help from a medicine ball it can work in a dynamic warmup paired with movements in a workout or as part of a cooldown or recovery strategy if the stretch causes pain in the front of your shoulder dial back the intensity or choose another chest stretch',\n 'input_ids': [1,\n  28705,\n  995,\n  460,\n  264,\n  1215,\n  10865,\n  1155,\n  279,\n  440,\n  693,\n  7263,\n  395,\n  6377,\n  304,\n  401,\n  7173,\n  5202,\n  4224,\n  28723,\n  260,\n  17484,\n  6031,\n  395,\n  1656,\n  28725,\n  3116,\n  28725,\n  304,\n  5307,\n  28723,\n  1992,\n  19571,\n  395,\n  3734,\n  2284,\n  18936,\n  2783,\n  8760,\n  346,\n  28723,\n  260,\n  27038,\n  26299,\n  28725,\n  521,\n  761,\n  745,\n  28725,\n  27425,\n  5200,\n  28725,\n  442,\n  7087,\n  3036,\n  28723,\n  25217,\n  4802,\n  497,\n  11711,\n  4968,\n  1467,\n  304,\n  14139,\n  2574,\n  28723,\n  2287,\n  774,\n  22478,\n  28747,\n  1912,\n  347,\n  684,\n  9095,\n  4374,\n  8118,\n  14742,\n  28705,\n  13,\n  13,\n  2287,\n  774,\n  26307,\n  28747,\n  272,\n  9095,\n  4374,\n  8118,\n  14742,\n  349,\n  264,\n  3588,\n  14742,\n  354,\n  272,\n  284,\n  3776,\n  282,\n  15922,\n  369,\n  541,\n  347,\n  1269,\n  680,\n  10616,\n  395,\n  1316,\n  477,\n  264,\n  12502,\n  4374,\n  378,\n  541,\n  771,\n  297,\n  264,\n  10616,\n  6100,\n  715,\n  5881,\n  1360,\n  395,\n  15071,\n  297,\n  264,\n  26039,\n  442,\n  390,\n  744,\n  302,\n  264,\n  1001,\n  738,\n  656,\n  442,\n  12106,\n  7213,\n  513,\n  272,\n  14742,\n  10110,\n  3358,\n  297,\n  272,\n  2778,\n  302,\n  574,\n  7793,\n  14262,\n  852,\n  272,\n  16800,\n  442,\n  4987,\n  1698,\n  8118,\n  14742,\n  28705,\n  2],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(tokenized_train_dataset[0]['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-03-18T14:58:58.012915Z","iopub.execute_input":"2024-03-18T14:58:58.013286Z","iopub.status.idle":"2024-03-18T14:58:58.022605Z","shell.execute_reply.started":"2024-03-18T14:58:58.013253Z","shell.execute_reply":"2024-03-18T14:58:58.021446Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'<s>  You are a very helpful assitant who helps with Health and Fitness related questions.     Always assist with care, respect, and truth. Respond with utmost utility yet securely.     Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity.    ### Question: tell be about exercise ball chest stretch \\n\\n    ### Answer: the exercise ball chest stretch is a simple stretch for the pectoral muscles that can be made more dynamic with help from a medicine ball it can work in a dynamic warmup paired with movements in a workout or as part of a cooldown or recovery strategy if the stretch causes pain in the front of your shoulder dial back the intensity or choose another chest stretch </s>'"},"metadata":{}}]},{"cell_type":"code","source":"max_length = 512 \n# This was an appropriate max length for my dataset\n\ndef generate_and_tokenize_prompt2(prompt):\n    result = tokenizer(\n        formatting_func(prompt),\n        truncation=True,\n        max_length=max_length,\n        padding=\"max_length\",\n    )\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:00:15.956936Z","iopub.execute_input":"2024-03-18T15:00:15.957651Z","iopub.status.idle":"2024-03-18T15:00:15.962683Z","shell.execute_reply.started":"2024-03-18T15:00:15.957613Z","shell.execute_reply":"2024-03-18T15:00:15.961790Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\ntokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:00:17.870343Z","iopub.execute_input":"2024-03-18T15:00:17.871005Z","iopub.status.idle":"2024-03-18T15:00:18.695620Z","shell.execute_reply.started":"2024-03-18T15:00:17.870973Z","shell.execute_reply":"2024-03-18T15:00:18.694692Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/742 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20892d908aeb41aa8067b7030532965b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/186 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bae1f2d6dbbe4d80a9a5bf332f1b4aa3"}},"metadata":{}}]},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:26.193221Z","iopub.execute_input":"2024-03-18T15:01:26.193609Z","iopub.status.idle":"2024-03-18T15:01:26.311224Z","shell.execute_reply.started":"2024-03-18T15:01:26.193579Z","shell.execute_reply":"2024-03-18T15:01:26.310421Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:28.552285Z","iopub.execute_input":"2024-03-18T15:01:28.552962Z","iopub.status.idle":"2024-03-18T15:01:28.557993Z","shell.execute_reply.started":"2024-03-18T15:01:28.552924Z","shell.execute_reply":"2024-03-18T15:01:28.557113Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:30.504949Z","iopub.execute_input":"2024-03-18T15:01:30.505630Z","iopub.status.idle":"2024-03-18T15:01:30.513925Z","shell.execute_reply.started":"2024-03-18T15:01:30.505593Z","shell.execute_reply":"2024-03-18T15:01:30.512897Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"trainable params: 0 || all params: 3752071168 || trainable%: 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:32.585003Z","iopub.execute_input":"2024-03-18T15:01:32.585911Z","iopub.status.idle":"2024-03-18T15:01:32.593212Z","shell.execute_reply.started":"2024-03-18T15:01:32.585874Z","shell.execute_reply":"2024-03-18T15:01:32.592209Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32000, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): MistralRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): MistralRMSNorm()\n        (post_attention_layernorm): MistralRMSNorm()\n      )\n    )\n    (norm): MistralRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=32,\n    lora_alpha=64,\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n        \"lm_head\",\n    ],\n    bias=\"none\",\n    lora_dropout=0.05,  # Conventional\n    task_type=\"CAUSAL_LM\",\n)\n\nmodel = get_peft_model(model, config)\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:34.936251Z","iopub.execute_input":"2024-03-18T15:01:34.937112Z","iopub.status.idle":"2024-03-18T15:01:36.364475Z","shell.execute_reply.started":"2024-03-18T15:01:34.937064Z","shell.execute_reply":"2024-03-18T15:01:36.363441Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:36.366400Z","iopub.execute_input":"2024-03-18T15:01:36.367142Z","iopub.status.idle":"2024-03-18T15:01:36.387279Z","shell.execute_reply.started":"2024-03-18T15:01:36.367102Z","shell.execute_reply":"2024-03-18T15:01:36.386403Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm()\n            (post_attention_layernorm): MistralRMSNorm()\n          )\n        )\n        (norm): MistralRMSNorm()\n      )\n      (lm_head): lora.Linear(\n        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n        (lora_dropout): ModuleDict(\n          (default): Dropout(p=0.05, inplace=False)\n        )\n        (lora_A): ModuleDict(\n          (default): Linear(in_features=4096, out_features=32, bias=False)\n        )\n        (lora_B): ModuleDict(\n          (default): Linear(in_features=32, out_features=32000, bias=False)\n        )\n        (lora_embedding_A): ParameterDict()\n        (lora_embedding_B): ParameterDict()\n      )\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import FullyShardedDataParallelPlugin, Accelerator\nfrom torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n\nfsdp_plugin = FullyShardedDataParallelPlugin(\n    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n)\n\naccelerator = Accelerator(fsdp_plugin=fsdp_plugin)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:39.756327Z","iopub.execute_input":"2024-03-18T15:01:39.756974Z","iopub.status.idle":"2024-03-18T15:01:39.770532Z","shell.execute_reply.started":"2024-03-18T15:01:39.756934Z","shell.execute_reply":"2024-03-18T15:01:39.769642Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.device_count() > 1: # If more than 1 GPU\n    model.is_parallelizable = True\n    model.model_parallel = True","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:40.892709Z","iopub.execute_input":"2024-03-18T15:01:40.893102Z","iopub.status.idle":"2024-03-18T15:01:40.898248Z","shell.execute_reply.started":"2024-03-18T15:01:40.893055Z","shell.execute_reply":"2024-03-18T15:01:40.897145Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = accelerator.prepare_model(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:01:42.732498Z","iopub.execute_input":"2024-03-18T15:01:42.733646Z","iopub.status.idle":"2024-03-18T15:01:42.739098Z","shell.execute_reply.started":"2024-03-18T15:01:42.733588Z","shell.execute_reply":"2024-03-18T15:01:42.737796Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import transformers\nfrom datetime import datetime\n\nproject = \"health-fitness-finetune-v2\"\nbase_model_name = \"mistral\"\nrun_name = base_model_name + \"-\" + project\noutput_dir = \"./\" + run_name\n\ntrainer = transformers.Trainer(\n    model=model,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    args=transformers.TrainingArguments(\n        output_dir=output_dir,\n        warmup_steps=1,\n        per_device_train_batch_size=4,\n        gradient_accumulation_steps=2,\n        gradient_checkpointing=True,\n        max_steps=150,\n        learning_rate=2.5e-5, # Want a small lr for finetuning\n#         bf16=True,\n        fp16=True,\n        optim=\"paged_adamw_8bit\",\n        logging_steps=25,              # When to start reporting loss\n        logging_dir=\"./logs\",        # Directory for storing logs\n        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n        save_steps=25,                # Save checkpoints every 50 steps\n        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n        do_eval=True,                # Perform evaluation at the end of training\n        push_to_hub = True,\n        hub_model_id = \"mistral-7B-finetune-health-fitness-v2\",\n        # report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n    ),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\n\nmodel.config.use_cache = False  # silence the warnings. Please re-enable for inference!\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:03:11.296710Z","iopub.execute_input":"2024-03-18T15:03:11.297468Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240318_150352-x92ssifv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ramachaitanya0/huggingface/runs/x92ssifv' target=\"_blank\">mistral-health-fitness-finetune-v2-2024-03-18-15-03</a></strong> to <a href='https://wandb.ai/ramachaitanya0/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ramachaitanya0/huggingface' target=\"_blank\">https://wandb.ai/ramachaitanya0/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ramachaitanya0/huggingface/runs/x92ssifv' target=\"_blank\">https://wandb.ai/ramachaitanya0/huggingface/runs/x92ssifv</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='176' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [176/200 55:46 < 07:41, 0.05 it/s, Epoch 1.88/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.515500</td>\n      <td>0.857057</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.810700</td>\n      <td>0.755010</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.752300</td>\n      <td>0.716691</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.685300</td>\n      <td>0.697355</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.588100</td>\n      <td>0.683605</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.555600</td>\n      <td>0.667956</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='4' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 4/24 00:13 < 01:29, 0.22 it/s]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# trainer.push_to_hub(\"ramachaitanya22/mistral-7B-finetune-health-fitness\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:52:34.959484Z","iopub.execute_input":"2024-03-13T20:52:34.959920Z","iopub.status.idle":"2024-03-13T20:53:05.062393Z","shell.execute_reply.started":"2024-03-13T20:52:34.959886Z","shell.execute_reply":"2024-03-13T20:53:05.061253Z"},"trusted":true},"execution_count":78,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e26969f8cce54f5d9452aa42964d38ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33325162fc324c61a56145db07679599"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/865M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b68939bd6ac495bb10939b863196b9b"}},"metadata":{}},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ramachaitanya22/mistral-7B-finetune-health-fitness/commit/0453c4ebdbf0462a0ed55c9a026ca194323e5a11', commit_message='ramachaitanya22/mistral-7B-finetune-health-fitness', commit_description='', oid='0453c4ebdbf0462a0ed55c9a026ca194323e5a11', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nbase_model_id = \"mistralai/Mistral-7B-v0.1\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16\n    \n)\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    base_model_id,  # Mistral, same as before\n    quantization_config=bnb_config,  # Same quantization config as before\n    device_map=\"auto\",\n    trust_remote_code=True,\n    \n)\n\neval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T21:03:19.180469Z","iopub.execute_input":"2024-03-13T21:03:19.181698Z","iopub.status.idle":"2024-03-13T21:03:36.126563Z","shell.execute_reply.started":"2024-03-13T21:03:19.181657Z","shell.execute_reply":"2024-03-13T21:03:36.125739Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16554ec338be4abc8af84ec1f2817a44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f591baec6644f548db0fc81a75497d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91216d9e7e26471ca48aaab305d42516"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff8e299f55604567bdc9c31ba07d895d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ceb95fd741c4f3fa16b4d1be7ed2fa0"}},"metadata":{}}]},{"cell_type":"code","source":"from peft import PeftModel\nft_model = PeftModel.from_pretrained(base_model, \"ramachaitanya22/mistral-7B-finetune-health-fitness\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T21:03:36.127746Z","iopub.execute_input":"2024-03-13T21:03:36.128053Z","iopub.status.idle":"2024-03-13T21:03:58.868498Z","shell.execute_reply.started":"2024-03-13T21:03:36.128028Z","shell.execute_reply":"2024-03-13T21:03:58.867575Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c7eb61d33024cacb72c32ee1b4c03e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/865M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54b719f23282437fa83d85782dd67051"}},"metadata":{}}]},{"cell_type":"code","source":"eval_prompt = \"can you recommend effective ab exercises:  # \"\nmodel_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n\nft_model.eval()\nwith torch.no_grad():\n    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T21:03:58.870586Z","iopub.execute_input":"2024-03-13T21:03:58.870891Z","iopub.status.idle":"2024-03-13T21:04:33.951270Z","shell.execute_reply.started":"2024-03-13T21:03:58.870866Z","shell.execute_reply":"2024-03-13T21:04:33.950170Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n2024-03-13 21:04:04.797167: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-13 21:04:04.800313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-13 21:04:05.054539: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"can you recommend effective ab exercises:  # 1. plank with leg raise:  the plank is a classic core exercise that targets all of the muscles in your midsection, including your abs and obliques. to make it more challenging, add a leg raise by lifting one or both legs off the ground while holding the plank position. this variation will work your lower abs as well as your upper abs.\n ### 2. bicycle crunch:  the bicycle crunch is another popular move for targeting all\n","output_type":"stream"}]},{"cell_type":"code","source":"from pprint import pprint\n\nwith torch.no_grad():\n    output = eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True)\n    pprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T21:05:12.555529Z","iopub.execute_input":"2024-03-13T21:05:12.556944Z","iopub.status.idle":"2024-03-13T21:05:26.524359Z","shell.execute_reply.started":"2024-03-13T21:05:12.556910Z","shell.execute_reply":"2024-03-13T21:05:26.523353Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"('can you recommend effective ab exercises:  # 1. plank with leg raise:  the '\n 'plank is a classic core exercise that targets all of the muscles in your '\n 'midsection, including your abs and obliques. to make it more challenging, '\n 'add a leg raise by lifting one or both legs off the ground while holding the '\n 'plank position. this variation will work your lower abs as well as your '\n 'upper abs.\\n'\n ' ### 2. bicycle crunch:  the bicycle crunch is another popular move for '\n 'targeting all')\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}